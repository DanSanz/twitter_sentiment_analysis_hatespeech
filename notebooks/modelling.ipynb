{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "from datetime import datetime  \n",
    "from nltk.tokenize import word_tokenize  \n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import ttest_ind\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder, LabelBinarizer, OneHotEncoder\n",
    "\n",
    "from sklearn.metrics import accuracy_score,roc_auc_score, f1_score, recall_score\n",
    "from sklearn.metrics import  roc_curve, confusion_matrix, precision_score\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "# function to make n-grams\n",
    "from nltk.util import ngrams \n",
    "from nltk import everygrams\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# tfidf = TfidfVectorizer(vocabulary = myvocabulary, stop_words = 'english')\n",
    "# tfs = tfidf.fit_transform(corpus.values())\n",
    "\n",
    "from gensim.corpora import Dictionary\n",
    "import itertools\n",
    "from collections import defaultdict\n",
    "from wordcloud import WordCloud\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/processed/data_for_modelling.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the tf-idf object\n",
    "tfidf_vectors = TfidfVectorizer(max_df=0.90, min_df=2, max_features=9000, \n",
    "                                stop_words='english',\n",
    "                                ngram_range=(1, 3))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF feature matrix\n",
    "tfidf = tfidf_vectors.fit_transform(df['tweet_without_stopwords_and_2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vector = pd.DataFrame(tfidf.todense(),columns = tfidf_vectors.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting into Training/Validation/Tes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = df['pos_label']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train , y_test = train_test_split(df_vector, target, \n",
    "                                                     test_size =.2, random_state=101 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of my training set is (33593, 9000)\n",
      "The shape of my training target is (33593,)\n",
      "The shape of my test set is (8399, 9000)\n",
      "The shape of my test target is (8399,)\n"
     ]
    }
   ],
   "source": [
    "print(f'The shape of my training set is {x_train.shape}')\n",
    "print(f'The shape of my training target is {y_train.shape}')\n",
    "print(f'The shape of my test set is {x_test.shape}')\n",
    "print(f'The shape of my test target is {y_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, x_val, Y_train , y_val = train_test_split(x_train,y_train, \n",
    "                                                     test_size =.2, random_state=101 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of my final training set is (26874, 9000)\n",
      "The shape of my final training target is (26874,)\n",
      "The shape of my validation set is (6719, 9000)\n",
      "The shape of my validation target is (6719,)\n"
     ]
    }
   ],
   "source": [
    "print(f'The shape of my final training set is {X_train.shape}')\n",
    "print(f'The shape of my final training target is {Y_train.shape}')\n",
    "print(f'The shape of my validation set is {x_val.shape}')\n",
    "print(f'The shape of my validation target is {y_val.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "logmodel = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logmodel.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing on validation\n",
    "y_hat_log = logmodel.predict(x_test)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9818390804597701"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, y_hat_log) # calculating f1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3970,  122],\n",
       "       [  36, 4271]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "confusion_matrix(y_test, y_hat_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3970, 122, 36, 4271)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, y_hat_log).ravel()\n",
    "tn, fp, fn, tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_proba = logmodel.predict_proba(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.06976815, 0.93023185],\n",
       "       [0.13261807, 0.86738193],\n",
       "       [0.98345116, 0.01654884],\n",
       "       [0.0489999 , 0.9510001 ],\n",
       "       [0.93550274, 0.06449726],\n",
       "       [0.13404968, 0.86595032],\n",
       "       [0.89883245, 0.10116755],\n",
       "       [0.87324718, 0.12675282],\n",
       "       [0.03572845, 0.96427155],\n",
       "       [0.03958806, 0.96041194]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat_proba[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21489    1\n",
       "14714    1\n",
       "12192    0\n",
       "31163    1\n",
       "6053     0\n",
       "        ..\n",
       "28287    0\n",
       "21944    1\n",
       "26081    1\n",
       "32660    0\n",
       "2474     0\n",
       "Name: pos_label, Length: 8399, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_hat_proba = y_hat_proba[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.93023185, 0.86738193, 0.01654884, 0.9510001 , 0.06449726,\n",
       "       0.86595032, 0.10116755, 0.12675282, 0.96427155, 0.96041194])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_hat_proba[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_neg = Y_hat_proba > .7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True, False, ...,  True, False, False])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
